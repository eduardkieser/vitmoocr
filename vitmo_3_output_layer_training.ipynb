{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hardie\\Anaconda3\\envs\\tflow\\python.exe\n",
      "C:\\Users\\Hardie\\Anaconda3\\envs\\tflow\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import os\n",
    "from time import time\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from KerasOCRTrainer2 import *\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create df to flow from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708004, 6)\n"
     ]
    }
   ],
   "source": [
    "# ubuntu\n",
    "file_list_2 = glob('../data/data2/*/*.png')\n",
    "shuffle(file_list_2)\n",
    "file_list_4 = glob('../data/data4/*/*.png')\n",
    "# shuffle(file_list_4)\n",
    "file_list_5 = glob('../data/data5/*/*.png')\n",
    "# shuffle(file_list_5)\n",
    "file_list_6 = glob('../data/data6/*/*.png')\n",
    "# shuffle(file_list_6)\n",
    "file_list_7 = glob('../data/data7/*/*.png')\n",
    "# shuffle(file_list_7)\n",
    "file_list_t = glob('../data/training_data/*/*.jpg')\n",
    "shuffle(file_list_t)\n",
    "print(f'this is a list{file_list_2}')\n",
    "\n",
    "file_list = file_list_2+file_list_4+file_list_5+file_list_6+file_list_7\n",
    "shuffle(file_list)\n",
    "\n",
    "file_list = [s.replace('/','\\\\') for s in file_list]\n",
    "\n",
    "print(f'this is a list{file_list}')\n",
    "\n",
    "# mac\n",
    "# file_list = glob('/Users/eduard/workspaces/ml_projects/keras/VitmoOCR/data2/*/*.png')\n",
    "# file_list = file_list+glob('/Users/eduard/workspaces/ml_projects/keras/VitmoOCR/training_data/numbers_96/*/*.jpg')\n",
    "df_lst = []\n",
    "for file_path in file_list:\n",
    "    label = file_path.split('\\\\')[-2]\n",
    "#     print(label)\n",
    "    alt_label = label\n",
    "    while len(alt_label)<3:\n",
    "        alt_label = ' '+alt_label\n",
    "    if alt_label == 'nan':\n",
    "        alt_label = '   '\n",
    "#     print(alt_label)    \n",
    "    l0,l1,l2 = alt_label\n",
    "    \n",
    "    df_lst.append({\n",
    "        'file_path': file_path,\n",
    "        'single_label':label,\n",
    "        'multi_label':np.array([l0,l1,l2]),\n",
    "        'l0':str(l0),\n",
    "        'l1':str(l1),\n",
    "        'l2':str(l2),\n",
    "#         'splitable':f'{l0},{l1},{l2}'\n",
    "    }\n",
    "    )\n",
    "df = pd.DataFrame(df_lst)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = range(0, 20+1)\n",
    "labels = [str(i) for i in labels]\n",
    "df_trunc = df[df['single_label'].isin(labels)]\n",
    "df = df_trunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hardie\\Anaconda3\\envs\\tflow\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>single_label</th>\n",
       "      <th>multi_label</th>\n",
       "      <th>l0</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>l0d</th>\n",
       "      <th>l1d</th>\n",
       "      <th>l2d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>..\\data\\data6\\11\\134_92_lQ8NQb_viSvjI.png</td>\n",
       "      <td>11</td>\n",
       "      <td>[ , 1, 1]</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>..\\data\\data2\\15\\164_115_GCMkFA_xCmCXm.png</td>\n",
       "      <td>15</td>\n",
       "      <td>[ , 1, 5]</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>..\\data\\data4\\14\\230_148_VAJvqs_zcwpMr.png</td>\n",
       "      <td>14</td>\n",
       "      <td>[ , 1, 4]</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>..\\data\\data4\\14\\221_155_pcMhYN_htbKWm.png</td>\n",
       "      <td>14</td>\n",
       "      <td>[ , 1, 4]</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>..\\data\\data6\\10\\158_93_4PAQje_xmbaMp.png</td>\n",
       "      <td>10</td>\n",
       "      <td>[ , 1, 0]</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     file_path single_label multi_label l0 l1  \\\n",
       "0    ..\\data\\data6\\11\\134_92_lQ8NQb_viSvjI.png           11   [ , 1, 1]     1   \n",
       "12  ..\\data\\data2\\15\\164_115_GCMkFA_xCmCXm.png           15   [ , 1, 5]     1   \n",
       "18  ..\\data\\data4\\14\\230_148_VAJvqs_zcwpMr.png           14   [ , 1, 4]     1   \n",
       "47  ..\\data\\data4\\14\\221_155_pcMhYN_htbKWm.png           14   [ , 1, 4]     1   \n",
       "48   ..\\data\\data6\\10\\158_93_4PAQje_xmbaMp.png           10   [ , 1, 0]     1   \n",
       "\n",
       "   l2                                l0d                                l1d  \\\n",
       "0   1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "12  5  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "18  4  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "47  4  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "48  0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                  l2d  \n",
       "0   [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "12  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "18  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "47  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "48  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot(cat):\n",
    "    categories = [' ','0','1','2','3','4','5','6','7','8','9']\n",
    "    return (cat==np.array(categories) ).astype(int).tolist()\n",
    "\n",
    "categories = [' ','0','1','2','3','4','5','6','7','8','9']\n",
    "for col in ['l0','l1','l2']:\n",
    "    df[col+'d'] = df[col].apply(one_hot)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=84x122 at 0x1B6978F0320>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_perspective(img):\n",
    "#     if np.random.randint(3)!=0:\n",
    "#         pass\n",
    "#     else:\n",
    "#         img= np.rot90(img)\n",
    "    \n",
    "    \n",
    "    # only apply to every n_th image\n",
    "    if np.random.randint(3)!=0:\n",
    "        return img\n",
    "    MAX_CHANGE = 0.2\n",
    "    a = np.random.rand(8).reshape(4,2)\n",
    "    width, height = img.shape[:2]\n",
    "    scale_factor = min(width,height)\n",
    "    a = a*scale_factor*MAX_CHANGE\n",
    "    pts1 = np.float32([\n",
    "        [0,0],\n",
    "        [width,0],\n",
    "        [width,height],\n",
    "        [0,height]\n",
    "    ])\n",
    "    pts2 = np.float32([\n",
    "        [0+a[0,0],0+a[0,1]],\n",
    "        [width-a[1,0],0+a[1,1]],\n",
    "        [width-a[2,0],height-a[2,1]],\n",
    "        [0+a[3,0],height-a[3,1]]\n",
    "    ])\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    img = cv2.warpPerspective(img, M, (height,width))\n",
    "    \n",
    "    return img\n",
    "\n",
    "path = file_list[0]\n",
    "img = cv2.imread(path)\n",
    "img = random_perspective(img)\n",
    "\n",
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hardie\\Anaconda3\\envs\\tflow\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:211: UserWarning: `classes` will be ignored given the class_mode=\"multi_output\"\n",
      "  .format(self.class_mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40275 validated image filenames.\n",
      "Found 4474 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "im_size = 48\n",
    "ks = 5\n",
    "\n",
    "mini_df = df\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    validation_split=0.1,\n",
    "    preprocessing_function = random_perspective\n",
    ")\n",
    "\n",
    "y_col = ['l0d','l1d','l2d']\n",
    "class_mode = 'multi_output'\n",
    "\n",
    "dirt = 'C:\\\\Users\\\\Hardie\\\\Desktop\\\\Eduard Model\\\\data'\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    mini_df, directory=dirt, x_col='file_path', y_col=y_col,\n",
    "    target_size=(im_size, im_size), color_mode='rgb', class_mode=class_mode, \n",
    "    subset=\"training\", classes=categories,\n",
    "    batch_size=1024, seed=42)\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "    mini_df, directory=dirt, x_col='file_path', y_col=y_col,\n",
    "    target_size=(im_size, im_size), color_mode='rgb', class_mode=class_mode, \n",
    "    subset=\"validation\", classes=categories,\n",
    "    batch_size=1024, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 48, 48, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 48, 48, 3)    12          input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 48, 48, 16)   448         batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 48, 48, 16)   64          conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 48, 48, 16)   0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 48, 48, 16)   2320        activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 48, 48, 16)   64          conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 48, 48, 16)   0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 48, 48, 16)   2320        activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 48, 48, 16)   64          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, 48, 48, 16)   0           activation_166[0][0]             \n",
      "                                                                 batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 48, 48, 16)   0           add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 48, 48, 16)   2320        activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 48, 48, 16)   64          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 48, 48, 16)   0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 48, 48, 16)   2320        activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 48, 48, 16)   64          conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 48, 48, 16)   0           activation_168[0][0]             \n",
      "                                                                 batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 48, 48, 16)   0           add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 48, 48, 16)   2320        activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 48, 48, 16)   64          conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 48, 48, 16)   0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 48, 48, 16)   2320        activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 48, 48, 16)   64          conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 48, 48, 16)   0           activation_170[0][0]             \n",
      "                                                                 batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 48, 48, 16)   0           add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 24, 24, 32)   4640        activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 24, 24, 32)   128         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 24, 24, 32)   0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 24, 24, 32)   9248        activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 24, 24, 32)   544         activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 24, 24, 32)   128         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 24, 24, 32)   0           conv2d_195[0][0]                 \n",
      "                                                                 batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 24, 24, 32)   0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 24, 24, 32)   9248        activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 24, 24, 32)   128         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 24, 24, 32)   0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 24, 24, 32)   9248        activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 24, 24, 32)   128         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 24, 24, 32)   0           activation_174[0][0]             \n",
      "                                                                 batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 24, 24, 32)   0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 24, 24, 32)   9248        activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 24, 24, 32)   128         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 24, 24, 32)   0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 24, 24, 32)   9248        activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 24, 24, 32)   128         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 24, 24, 32)   0           activation_176[0][0]             \n",
      "                                                                 batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 24, 24, 32)   0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 12, 12, 64)   18496       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 12, 12, 64)   256         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 12, 12, 64)   0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 12, 12, 64)   36928       activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 12, 12, 64)   2112        activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 12, 12, 64)   256         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 12, 12, 64)   0           conv2d_202[0][0]                 \n",
      "                                                                 batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 12, 12, 64)   0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 12, 12, 64)   36928       activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 12, 12, 64)   256         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 12, 12, 64)   0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 12, 12, 64)   36928       activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 12, 12, 64)   256         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 12, 12, 64)   0           activation_180[0][0]             \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 12, 12, 64)   0           add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 12, 12, 64)   36928       activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 12, 12, 64)   256         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 12, 12, 64)   0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 12, 12, 64)   36928       activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 12, 12, 64)   256         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 12, 12, 64)   0           activation_182[0][0]             \n",
      "                                                                 batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 12, 12, 64)   0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 1, 1, 64)     0           activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 64)           0           average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "num1 (Dense)                    (None, 11)           715         flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "num2 (Dense)                    (None, 11)           715         flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "num3 (Dense)                    (None, 11)           715         flatten_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 275,949\n",
      "Trainable params: 274,567\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model built by Hardie\n",
    "# Lets use a ResNet, state of the art and tends to train easier.\n",
    "\n",
    "# Resnet code grabbed from:\n",
    "# https://keras.io/examples/cifar10_resnet/\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# Build the network using this function\n",
    "def resnet(input_shape, depth):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10) REMOVED\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # On eduards request\n",
    "    x = BatchNormalization()(inputs)    \n",
    "    #x = resnet_layer(inputs=inputs)\n",
    "    x = resnet_layer(x)\n",
    "    \n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Hardie: Hack to get the resnet to work with current workflow\n",
    "    #dense1 = Dense(200,activation='relu')(x) # \n",
    "    num1 = Dense(11,activation='softmax',name='num1')(x)\n",
    "    num2 = Dense(11,activation='softmax',name='num2')(x)\n",
    "    num3 = Dense(11,activation='softmax',name='num3')(x)\n",
    "    \n",
    "#     outputs = Dense(num_classes,\n",
    "#                     activation='softmax',\n",
    "#                     kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    # Old: model = Model(inputs=inputs, outputs=outputs)\n",
    "    model = Model(inputs = inputs, outputs=[num1,num2,num3])\n",
    "    return model\n",
    "\n",
    "shape=(im_size, im_size, 3)\n",
    "model = resnet(shape, 20)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # kernale size\n",
    "    ks = 5\n",
    "    # number of filters\n",
    "    nf = 32\n",
    "    input_img = Input(shape=(im_size, im_size, 3))\n",
    "    print(input_img)\n",
    "    # gs_img = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(input_img)\n",
    "    conv1 = Conv2D(nf, (ks, ks), strides=2, padding='same', activation='relu')(input_img)\n",
    "    drop1 = Dropout(0.05)(conv1)\n",
    "    conv2 = Conv2D(nf, (ks, ks), strides=2, padding='same', activation='relu')(drop1)\n",
    "    drop2 = Dropout(0.05)(conv2)\n",
    "    conv3 = Conv2D(nf, (ks, ks), strides=2, padding='same', activation='relu')(drop2)\n",
    "    flat1  = Flatten()(conv3)\n",
    "    dense1 = Dense(256,activation='relu')(flat1)\n",
    "    num1 = Dense(11,activation='softmax',name='num1')(dense1)\n",
    "    num2 = Dense(11,activation='softmax',name='num2')(dense1)\n",
    "    num3 = Dense(11,activation='softmax',name='num3')(dense1)\n",
    "\n",
    "    # output = keras.layers.concatenate([num1,num2,num3])\n",
    "    # output = [num1,num2,num3]?\n",
    "    model = Model(inputs = input_img, outputs=[num1,num2,num3])\n",
    "    model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 48, 48, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 48, 48, 3)    12          input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 48, 48, 16)   448         batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 48, 48, 16)   64          conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 48, 48, 16)   0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 48, 48, 16)   2320        activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 48, 48, 16)   64          conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 48, 48, 16)   0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 48, 48, 16)   2320        activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 48, 48, 16)   64          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, 48, 48, 16)   0           activation_166[0][0]             \n",
      "                                                                 batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 48, 48, 16)   0           add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 48, 48, 16)   2320        activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 48, 48, 16)   64          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 48, 48, 16)   0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 48, 48, 16)   2320        activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 48, 48, 16)   64          conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 48, 48, 16)   0           activation_168[0][0]             \n",
      "                                                                 batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 48, 48, 16)   0           add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 48, 48, 16)   2320        activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 48, 48, 16)   64          conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 48, 48, 16)   0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 48, 48, 16)   2320        activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 48, 48, 16)   64          conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 48, 48, 16)   0           activation_170[0][0]             \n",
      "                                                                 batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 48, 48, 16)   0           add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 24, 24, 32)   4640        activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 24, 24, 32)   128         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 24, 24, 32)   0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 24, 24, 32)   9248        activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 24, 24, 32)   544         activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 24, 24, 32)   128         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 24, 24, 32)   0           conv2d_195[0][0]                 \n",
      "                                                                 batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 24, 24, 32)   0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 24, 24, 32)   9248        activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 24, 24, 32)   128         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 24, 24, 32)   0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 24, 24, 32)   9248        activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 24, 24, 32)   128         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 24, 24, 32)   0           activation_174[0][0]             \n",
      "                                                                 batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 24, 24, 32)   0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 24, 24, 32)   9248        activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 24, 24, 32)   128         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 24, 24, 32)   0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 24, 24, 32)   9248        activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 24, 24, 32)   128         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 24, 24, 32)   0           activation_176[0][0]             \n",
      "                                                                 batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 24, 24, 32)   0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 12, 12, 64)   18496       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 12, 12, 64)   256         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 12, 12, 64)   0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 12, 12, 64)   36928       activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 12, 12, 64)   2112        activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 12, 12, 64)   256         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 12, 12, 64)   0           conv2d_202[0][0]                 \n",
      "                                                                 batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 12, 12, 64)   0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 12, 12, 64)   36928       activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 12, 12, 64)   256         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 12, 12, 64)   0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 12, 12, 64)   36928       activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 12, 12, 64)   256         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 12, 12, 64)   0           activation_180[0][0]             \n",
      "                                                                 batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 12, 12, 64)   0           add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 12, 12, 64)   36928       activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 12, 12, 64)   256         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 12, 12, 64)   0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 12, 12, 64)   36928       activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 12, 12, 64)   256         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 12, 12, 64)   0           activation_182[0][0]             \n",
      "                                                                 batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 12, 12, 64)   0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 1, 1, 64)     0           activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 64)           0           average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "num1 (Dense)                    (None, 11)           715         flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "num2 (Dense)                    (None, 11)           715         flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "num3 (Dense)                    (None, 11)           715         flatten_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 275,949\n",
      "Trainable params: 274,567\n",
      "Non-trainable params: 1,382\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet8'\n",
    "tensorboard = TensorBoard(log_dir=f'logs\\\\{model_name}')\n",
    "model_path = 'models\\\\resnet'\n",
    "all_checkpoint_path = f'{model_path}''\\\\ep{epoch:02d}-va{val_loss:.2f}.hdf5'\n",
    "save_all_callback = ModelCheckpoint(\n",
    "        all_checkpoint_path, \n",
    "        monitor='val_loss',\n",
    "        save_best_only=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(f'{model_path}''\\\\ep01-va0.12.hdf5')\n",
    "model.compile(optimizers.Adam(lr=0.0001),loss=[\"categorical_crossentropy\"]*3,metrics=[\"accuracy\"],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "39/39 [==============================] - 57s 1s/step - loss: 0.1924 - num1_loss: 1.0888e-04 - num2_loss: 0.0123 - num3_loss: 0.0492 - num1_acc: 1.0000 - num2_acc: 0.9954 - num3_acc: 0.9851 - val_loss: 0.2252 - val_num1_loss: 2.1279e-04 - val_num2_loss: 0.0219 - val_num3_loss: 0.0725 - val_num1_acc: 1.0000 - val_num2_acc: 0.9929 - val_num3_acc: 0.9783\n",
      "Epoch 2/60\n",
      "39/39 [==============================] - 57s 1s/step - loss: 0.1845 - num1_loss: 5.6450e-05 - num2_loss: 0.0116 - num3_loss: 0.0424 - num1_acc: 1.0000 - num2_acc: 0.9955 - num3_acc: 0.9873 - val_loss: 0.2196 - val_num1_loss: 1.3972e-04 - val_num2_loss: 0.0167 - val_num3_loss: 0.0725 - val_num1_acc: 1.0000 - val_num2_acc: 0.9941 - val_num3_acc: 0.9790\n",
      "Epoch 3/60\n",
      "39/39 [==============================] - 57s 1s/step - loss: 0.1857 - num1_loss: 3.7158e-05 - num2_loss: 0.0116 - num3_loss: 0.0440 - num1_acc: 1.0000 - num2_acc: 0.9956 - num3_acc: 0.9862 - val_loss: 0.2201 - val_num1_loss: 6.6798e-05 - val_num2_loss: 0.0184 - val_num3_loss: 0.0718 - val_num1_acc: 1.0000 - val_num2_acc: 0.9937 - val_num3_acc: 0.9790\n",
      "Epoch 4/60\n",
      "39/39 [==============================] - 56s 1s/step - loss: 0.1829 - num1_loss: 2.6506e-05 - num2_loss: 0.0110 - num3_loss: 0.0422 - num1_acc: 1.0000 - num2_acc: 0.9958 - num3_acc: 0.9868 - val_loss: 0.2140 - val_num1_loss: 5.5230e-05 - val_num2_loss: 0.0211 - val_num3_loss: 0.0633 - val_num1_acc: 1.0000 - val_num2_acc: 0.9912 - val_num3_acc: 0.9792\n",
      "Epoch 5/60\n",
      "39/39 [==============================] - 56s 1s/step - loss: 0.1789 - num1_loss: 2.0422e-05 - num2_loss: 0.0098 - num3_loss: 0.0398 - num1_acc: 1.0000 - num2_acc: 0.9963 - num3_acc: 0.9876 - val_loss: 0.2068 - val_num1_loss: 4.5183e-05 - val_num2_loss: 0.0156 - val_num3_loss: 0.0620 - val_num1_acc: 1.0000 - val_num2_acc: 0.9939 - val_num3_acc: 0.9807\n",
      "Epoch 6/60\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.1810 - num1_loss: 1.7264e-05 - num2_loss: 0.0111 - num3_loss: 0.0410 - num1_acc: 1.0000 - num2_acc: 0.9959 - num3_acc: 0.9873 - val_loss: 0.2265 - val_num1_loss: 3.0016e-05 - val_num2_loss: 0.0178 - val_num3_loss: 0.0799 - val_num1_acc: 1.0000 - val_num2_acc: 0.9929 - val_num3_acc: 0.9756\n",
      "Epoch 7/60\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.1784 - num1_loss: 1.4122e-05 - num2_loss: 0.0099 - num3_loss: 0.0399 - num1_acc: 1.0000 - num2_acc: 0.9964 - num3_acc: 0.9877 - val_loss: 0.2140 - val_num1_loss: 2.2115e-05 - val_num2_loss: 0.0178 - val_num3_loss: 0.0677 - val_num1_acc: 1.0000 - val_num2_acc: 0.9917 - val_num3_acc: 0.9792\n",
      "Epoch 8/60\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.1778 - num1_loss: 1.3000e-05 - num2_loss: 0.0102 - num3_loss: 0.0392 - num1_acc: 1.0000 - num2_acc: 0.9965 - num3_acc: 0.9877 - val_loss: 0.2129 - val_num1_loss: 2.3223e-05 - val_num2_loss: 0.0193 - val_num3_loss: 0.0655 - val_num1_acc: 1.0000 - val_num2_acc: 0.9922 - val_num3_acc: 0.9792\n",
      "Epoch 9/60\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.1751 - num1_loss: 1.1174e-05 - num2_loss: 0.0098 - num3_loss: 0.0374 - num1_acc: 1.0000 - num2_acc: 0.9962 - num3_acc: 0.9886 - val_loss: 0.2210 - val_num1_loss: 1.8422e-05 - val_num2_loss: 0.0178 - val_num3_loss: 0.0754 - val_num1_acc: 1.0000 - val_num2_acc: 0.9937 - val_num3_acc: 0.9766\n",
      "Epoch 10/60\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.1763 - num1_loss: 1.0245e-05 - num2_loss: 0.0108 - num3_loss: 0.0379 - num1_acc: 1.0000 - num2_acc: 0.9961 - num3_acc: 0.9883 - val_loss: 0.2135 - val_num1_loss: 1.0348e-05 - val_num2_loss: 0.0162 - val_num3_loss: 0.0698 - val_num1_acc: 1.0000 - val_num2_acc: 0.9932 - val_num3_acc: 0.9785\n",
      "Epoch 11/60\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.1766 - num1_loss: 7.8395e-06 - num2_loss: 0.0101 - num3_loss: 0.0392 - num1_acc: 1.0000 - num2_acc: 0.9963 - num3_acc: 0.9879 - val_loss: 0.2054 - val_num1_loss: 7.9856e-06 - val_num2_loss: 0.0174 - val_num3_loss: 0.0610 - val_num1_acc: 1.0000 - val_num2_acc: 0.9929 - val_num3_acc: 0.9819\n",
      "Epoch 12/60\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.1744 - num1_loss: 7.5986e-06 - num2_loss: 0.0103 - num3_loss: 0.0372 - num1_acc: 1.0000 - num2_acc: 0.9962 - num3_acc: 0.9883 - val_loss: 0.2133 - val_num1_loss: 9.8248e-06 - val_num2_loss: 0.0170 - val_num3_loss: 0.0695 - val_num1_acc: 1.0000 - val_num2_acc: 0.9944 - val_num3_acc: 0.9790\n",
      "Epoch 13/60\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.1734 - num1_loss: 7.3565e-06 - num2_loss: 0.0092 - num3_loss: 0.0375 - num1_acc: 1.0000 - num2_acc: 0.9969 - num3_acc: 0.9885 - val_loss: 0.2069 - val_num1_loss: 9.2063e-06 - val_num2_loss: 0.0158 - val_num3_loss: 0.0646 - val_num1_acc: 1.0000 - val_num2_acc: 0.9934 - val_num3_acc: 0.9807\n",
      "Epoch 14/60\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.1722 - num1_loss: 6.5955e-06 - num2_loss: 0.0093 - num3_loss: 0.0365 - num1_acc: 1.0000 - num2_acc: 0.9968 - num3_acc: 0.9890 - val_loss: 0.2066 - val_num1_loss: 9.1069e-06 - val_num2_loss: 0.0158 - val_num3_loss: 0.0646 - val_num1_acc: 1.0000 - val_num2_acc: 0.9924 - val_num3_acc: 0.9807\n",
      "Epoch 15/60\n",
      "39/39 [==============================] - 55s 1s/step - loss: 0.1697 - num1_loss: 6.0383e-06 - num2_loss: 0.0085 - num3_loss: 0.0351 - num1_acc: 1.0000 - num2_acc: 0.9970 - num3_acc: 0.9892 - val_loss: 0.2070 - val_num1_loss: 9.8507e-06 - val_num2_loss: 0.0167 - val_num3_loss: 0.0645 - val_num1_acc: 1.0000 - val_num2_acc: 0.9939 - val_num3_acc: 0.9792\n",
      "Epoch 16/60\n",
      "39/39 [==============================] - 53s 1s/step - loss: 0.1676 - num1_loss: 5.3715e-06 - num2_loss: 0.0089 - num3_loss: 0.0331 - num1_acc: 1.0000 - num2_acc: 0.9968 - num3_acc: 0.9901 - val_loss: 0.2075 - val_num1_loss: 7.5711e-06 - val_num2_loss: 0.0151 - val_num3_loss: 0.0668 - val_num1_acc: 1.0000 - val_num2_acc: 0.9951 - val_num3_acc: 0.9797\n",
      "Epoch 17/60\n",
      "39/39 [==============================] - 54s 1s/step - loss: 0.1726 - num1_loss: 5.3115e-06 - num2_loss: 0.0098 - num3_loss: 0.0374 - num1_acc: 1.0000 - num2_acc: 0.9967 - num3_acc: 0.9889 - val_loss: 0.2056 - val_num1_loss: 6.1921e-06 - val_num2_loss: 0.0172 - val_num3_loss: 0.0633 - val_num1_acc: 1.0000 - val_num2_acc: 0.9939 - val_num3_acc: 0.9817\n",
      "Epoch 18/60\n",
      "39/39 [==============================] - 59s 2s/step - loss: 0.1683 - num1_loss: 5.0162e-06 - num2_loss: 0.0085 - num3_loss: 0.0347 - num1_acc: 1.0000 - num2_acc: 0.9968 - num3_acc: 0.9896 - val_loss: 0.2057 - val_num1_loss: 7.1219e-06 - val_num2_loss: 0.0167 - val_num3_loss: 0.0641 - val_num1_acc: 1.0000 - val_num2_acc: 0.9937 - val_num3_acc: 0.9800\n",
      "Epoch 19/60\n",
      "22/39 [===============>..............] - ETA: 18s - loss: 0.1693 - num1_loss: 4.4576e-06 - num2_loss: 0.0094 - num3_loss: 0.0351 - num1_acc: 1.0000 - num2_acc: 0.9973 - num3_acc: 0.9898"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-faa855a5ad17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_all_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m       \u001b[0mbatch_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[1;34m(generator, mode)\u001b[0m\n\u001b[0;32m    360\u001b[0m   \u001b[1;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    777\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tflow\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tflow\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tflow\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tflow\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "# STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=60,\n",
    "                    callbacks = [tensorboard, save_all_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
